#!/usr/bin/env python3
import argparse
import csv
from collections import defaultdict
from datetime import datetime
from typing import DefaultDict, Optional

import matplotlib.pyplot as plt


def main() -> None:
    """
    Parses GPU metrics from a CSV file and generates plots for VRAM usage and
    GPU utilization over time.

    The script reads a CSV file generated by `nvidia-smi`, processes the data,
    and creates two plots: one for VRAM usage (in MiB) and one for GPU
    utilization (in %). The plots can be displayed on screen or saved to PNG
    files.
    """
    ap = argparse.ArgumentParser()
    ap.add_argument("csv_path", help="Path to the gpu_metrics.csv file")
    ap.add_argument("--show", action="store_true", help="Show plot window")
    ap.add_argument(
        "--out",
        type=str,
        default=None,
        help="Save plot to file (without extension)",
    )
    args = ap.parse_args()

    # Expected header names (note leading spaces from nvidia-smi CSV)
    TS = "timestamp"
    IDX = " index"
    NAME = " name"
    MEM = " memory.used [MiB]"
    UTIL = " utilization.gpu [%]"

    # Per-GPU series
    times_by_gpu: DefaultDict[str, list[float]] = defaultdict(list)
    vram_by_gpu: DefaultDict[str, list[int]] = defaultdict(list)
    util_by_gpu: DefaultDict[str, list[int]] = defaultdict(list)
    first_ts: Optional[datetime] = None

    try:
        with open(args.csv_path, encoding="utf-8") as f:
            reader = csv.reader(f)
            header = next(reader)

            for need in (TS, IDX, NAME, MEM, UTIL):
                if need not in header:
                    print(f"Missing expected column '{need}' in CSV header: {header}")
                    return

            ts_i = header.index(TS)
            idx_i = header.index(IDX)
            name_i = header.index(NAME)
            mem_i = header.index(MEM)
            util_i = header.index(UTIL)

            for row in reader:
                if not row:
                    continue
                try:
                    ts = datetime.strptime(row[ts_i], "%Y/%m/%d %H:%M:%S.%f")
                except ValueError:
                    # Fallback if no fractional seconds
                    ts = datetime.strptime(row[ts_i], "%Y/%m/%d %H:%M:%S")

                if first_ts is None:
                    first_ts = ts

                gpu_index = row[idx_i].strip()
                gpu_name = row[name_i].strip()
                key = f"GPU {gpu_index} â€” {gpu_name}"

                # Parse VRAM and util (strip units)
                vram = int(row[mem_i].replace(" MiB", "").strip())
                util = int(row[util_i].replace(" %", "").strip())

                times_by_gpu[key].append((ts - first_ts).total_seconds())
                vram_by_gpu[key].append(vram)
                util_by_gpu[key].append(util)

    except FileNotFoundError:
        print(f"Error: File not found at {args.csv_path}")
        return
    except (IOError, ValueError) as e:
        print(f"An error occurred: {e}")
        return

    if not times_by_gpu:
        print("No data to plot.")
        return

    # Optional truncation: stop shortly after the last nonzero VRAM across all GPUs
    last_idx_global = -1
    # Find shortest length among series so we can align indices safely
    min_len = min(len(v) for v in vram_by_gpu.values())
    for i in range(min_len - 1, -1, -1):
        any_nonzero = any(vram_by_gpu[key][i] > 0 for key in vram_by_gpu.keys())
        if any_nonzero:
            last_idx_global = min(i + 2, min_len)
            break

    if last_idx_global != -1:
        for key in list(times_by_gpu.keys()):
            times_by_gpu[key] = times_by_gpu[key][:last_idx_global]
            vram_by_gpu[key] = vram_by_gpu[key][:last_idx_global]
            util_by_gpu[key] = util_by_gpu[key][:last_idx_global]

    # Plot VRAM overlay
    plt.figure()
    for key in sorted(times_by_gpu.keys()):
        plt.plot(times_by_gpu[key], vram_by_gpu[key], label=key)
    plt.title("VRAM Usage Over Time (All GPUs)")
    plt.xlabel("Time (s)")
    plt.ylabel("VRAM Used (MiB)")
    plt.grid(True)
    plt.ylim(bottom=0)
    plt.legend(loc="best")
    if args.out:
        plt.savefig(f"{args.out}_vram.png", dpi=150, bbox_inches="tight")

    # Plot Utilization overlay
    plt.figure()
    for key in sorted(times_by_gpu.keys()):
        plt.plot(times_by_gpu[key], util_by_gpu[key], label=key)
    plt.title("GPU Utilization Over Time (All GPUs)")
    plt.xlabel("Time (s)")
    plt.ylabel("GPU Utilization (%)")
    plt.grid(True)
    plt.ylim(0, 105)
    plt.legend(loc="best")
    if args.out:
        plt.savefig(f"{args.out}_gpu_util.png", dpi=150, bbox_inches="tight")

    if args.show or not args.out:
        plt.show()


if __name__ == "__main__":
    main()
